{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:50:00.824665Z",
     "start_time": "2025-06-24T10:49:57.093199Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if not os.path.isdir('./figure/'):\n",
    "    \n",
    "    os.makedirs('./figure/')"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T10:50:03.852370Z",
     "start_time": "2025-06-24T10:50:03.244471Z"
    }
   },
   "source": [
    "# length of data\n",
    "lenT = 100\n",
    "\n",
    "# slope and intercept\n",
    "intercept = 4\n",
    "slope = 1.5\n",
    "#\n",
    "x_min = -2\n",
    "x_max = 2\n",
    "range_x = x_max-x_min\n",
    "# noise level noise越大分布越分散\n",
    "sig = 0.5\n",
    "x1 = x_min + range_x *np.random.rand(lenT)\n",
    "y = intercept + slope*x1 + sig*np.random.randn(lenT)\n",
    "#\n",
    "# add few outlier and assess their impact\n",
    "# m = 3\n",
    "# for i in range(m):\n",
    "#     y[i] = y[i]+10*np.random.randn(1)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(x1,y)\n",
    "plt.plot(x1, intercept + slope*x1, color='r')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:50:10.236942Z",
     "start_time": "2025-06-24T10:50:10.227149Z"
    }
   },
   "source": [
    "### Python Linear Regression Solver\n",
    "# Create the design matrix\n",
    "X = np.vstack([x1, np.ones(len(x1))]).T\n",
    "\n",
    "# Create linear regression object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict the y values\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Get slope (coefficient)&intercept\n",
    "slope2 = model.coef_[0]\n",
    "intercept2 = model.intercept_\n",
    "print(\"Slope:{:.3f}\".format(slope2))\n",
    "print(\"Intercept:{:.3f}\".format(intercept2))\n",
    "\n",
    "# Calculate R-square\n",
    "r_squared = r2_score(y, y_pred)\n",
    "print(\"R-square:\", r_squared)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope:1.406\n",
      "Intercept:3.983\n",
      "R-square: 0.9314057658668535\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:50:12.339388Z",
     "start_time": "2025-06-24T10:50:12.261870Z"
    }
   },
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(x1,y)\n",
    "plt.plot(x1, intercept  + slope*x1, color='r')\n",
    "plt.plot(x1, intercept2 + slope2*x1, color='g')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent (batch or vanilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:50:15.620112Z",
     "start_time": "2025-06-24T10:50:15.450990Z"
    }
   },
   "source": [
    "# entire dataset\n",
    "a = np.linspace(-20, 20, 50)\n",
    "b = np.linspace(-20, 20, 50)\n",
    "len1 = len(a)\n",
    "len2 = len(b)\n",
    "\n",
    "A, B = np.meshgrid(a,b)\n",
    "\n",
    "s = np.zeros((len2, len1))\n",
    "for i in np.arange(len1):\n",
    "    for j in np.arange(len2):\n",
    "        s[j,i] = np.sum((y-a[i]-b[j]*x1)**2)/lenT # mean squared error\n",
    "\n",
    "fig = plt.figure(figsize=(8,4)) # create a figure object\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.contour(A,B,s)\n",
    "ax1.scatter(intercept, slope, color='r')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.plot_surface(A, B, s, cmap=plt.cm.coolwarm)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x15e494410>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:50:18.353639Z",
     "start_time": "2025-06-24T10:50:18.348942Z"
    }
   },
   "source": [
    "# Gradient of our objective function\n",
    "def gradF2(params, y, x1):    \n",
    "    n = len(y)\n",
    "    intercept_ = params[0]\n",
    "    slope_ = params[1]\n",
    "    grad = np.array([-2*np.sum((y - intercept_ - slope_*x1))/n,\n",
    "                     -2*np.sum((y - intercept_ - slope_*x1)*x1)/n])\n",
    "    return grad"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Batch) Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T10:50:42.620791Z",
     "start_time": "2025-06-24T10:50:22.736176Z"
    }
   },
   "source": [
    "nIters = 50\n",
    "g1 = 0.1 # learning rate\n",
    "\n",
    "intercept_ = 40\n",
    "slope_ = -50\n",
    "x_i = np.array([intercept_, slope_])\n",
    "\n",
    "beta0 = np.zeros(nIters+1)\n",
    "beta1 = np.zeros(nIters+1)\n",
    "beta0[0] = intercept_\n",
    "beta1[0] = slope_\n",
    "\n",
    "for i in np.arange(nIters):\n",
    "    \n",
    "    delF = gradF2(x_i, y, x1);\n",
    "    x_i = x_i - g1*delF\n",
    "    beta0[i+1] = x_i[0]\n",
    "    beta1[i+1] = x_i[1]\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(14,6))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.contour(A,B,s)\n",
    "    ax1.plot(beta0[:i],beta1[:i],color='r')\n",
    "    ax1.scatter(beta0[:i],beta1[:i],color='k')\n",
    "    ax1.scatter(intercept, slope, color='r')\n",
    "    ax1.set_title('(Batch) Gradient Descent')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.scatter(x1,y)\n",
    "    ax2.plot(x1, beta0[i+1]+beta1[i+1]*x1, color='r')\n",
    "    #fig.savefig('figure/Batch_'+str(i)+'.png')\n",
    "    plt.pause(0.1) # number of seconds before updating the graph\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnIters = 50\\ng1 = 0.1 # learning rate\\n\\nintercept_ = 40\\nslope_ = -50\\nx_i = np.array([intercept_, slope_])\\n\\nbeta0 = np.zeros(nIters+1)\\nbeta1 = np.zeros(nIters+1)\\nbeta0[0] = intercept_\\nbeta1[0] = slope_\\n\\nfor i in np.arange(nIters):\\n\\n    delF = gradF2(x_i, y, x1);\\n    x_i = x_i - g1*delF\\n    beta0[i+1] = x_i[0]\\n    beta1[i+1] = x_i[1]\\n\\n    clear_output(wait=True)\\n\\n    fig = plt.figure(figsize=(14,6))\\n    ax1 = fig.add_subplot(121)\\n    ax1.contour(A,B,s)\\n    ax1.plot(beta0[:i],beta1[:i],color='r')\\n    ax1.scatter(beta0[:i],beta1[:i],color='k')\\n    ax1.scatter(intercept, slope, color='r')\\n    ax1.set_title('(Batch) Gradient Descent')\\n    ax2 = fig.add_subplot(122)\\n    ax2.scatter(x1,y)\\n    ax2.plot(x1, beta0[i+1]+beta1[i+1]*x1, color='r')\\n    #fig.savefig('figure/Batch_'+str(i)+'.png')\\n    plt.pause(0.1) # number of seconds before updating the graph\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T10:55:11.989041Z",
     "start_time": "2025-06-24T10:55:00.581951Z"
    }
   },
   "source": [
    "nIters = 5\n",
    "g1 = 0.1 # learning rate\n",
    "intercept_ = 40\n",
    "slope_ = -50\n",
    "x_i = np.array([intercept_, slope_])\n",
    "\n",
    "batchSize = 30\n",
    "#numOfBatches = 20\n",
    "numOfBatches = np.ceil(lenT/batchSize)\n",
    "\n",
    "beta0 = np.zeros(int(nIters*numOfBatches+1))\n",
    "beta1 = np.zeros(int(nIters*numOfBatches+1))\n",
    "beta0[0] = intercept_\n",
    "beta1[0] = slope_\n",
    "\n",
    "for i in np.arange(nIters-1):\n",
    "    for j in np.arange(numOfBatches): \n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        start = int(j*batchSize)\n",
    "        finish =int(min((j+1)*batchSize, lenT-1))\n",
    "        \n",
    "        xHat = x1[start:finish]\n",
    "        yHat = y[start:finish]\n",
    "        delF = gradF2(x_i, yHat, xHat);\n",
    "        \n",
    "        for i1 in np.arange(len1): \n",
    "            for j1 in np.arange(len2):\n",
    "                s[j1,i1] = np.sum((yHat-a[i1]-b[j1]*xHat)**2)/batchSize\n",
    "        \n",
    "        x_i = x_i - g1*delF\n",
    "        idx = int(i*numOfBatches+j+1)\n",
    "        beta0[idx] = x_i[0]\n",
    "        beta1[idx] = x_i[1]\n",
    "        \n",
    "        fig = plt.figure(figsize=(14,6))\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.contour(A,B,s)\n",
    "        ax1.plot(beta0[:idx+1],beta1[:idx+1],color='r')\n",
    "        ax1.scatter(beta0[:idx+1],beta1[:idx+1],color='k')\n",
    "        ax1.scatter(intercept, slope, color='r')\n",
    "        ax1.set_title('Mini-Batch Gradient Descent')\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.scatter(x1,y)\n",
    "        ax2.plot(x1,beta0[idx]+beta1[idx]*x1,color='r')\n",
    "        #fig.savefig('figure/miniBatch_'+str(i)+'_'+str(j)+'.png')\n",
    "        plt.pause(0.1) # number of seconds before updating the graph\n",
    "        plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnIters = 5\\ng1 = 0.1 # learning rate\\nintercept_ = 40\\nslope_ = -50\\nx_i = np.array([intercept_, slope_])\\n\\nbatchSize = 30\\n#numOfBatches = 20\\nnumOfBatches = np.ceil(lenT/batchSize)\\n\\nbeta0 = np.zeros(int(nIters*numOfBatches+1))\\nbeta1 = np.zeros(int(nIters*numOfBatches+1))\\nbeta0[0] = intercept_\\nbeta1[0] = slope_\\n\\nfor i in np.arange(nIters-1):\\n    for j in np.arange(numOfBatches): \\n\\n        clear_output(wait=True)\\n\\n        start = int(j*batchSize)\\n        finish =int(min((j+1)*batchSize, lenT-1))\\n\\n        xHat = x1[start:finish]\\n        yHat = y[start:finish]\\n        delF = gradF2(x_i, yHat, xHat);\\n\\n        for i1 in np.arange(len1): \\n            for j1 in np.arange(len2):\\n                s[j1,i1] = np.sum((yHat-a[i1]-b[j1]*xHat)**2)/batchSize\\n\\n        x_i = x_i - g1*delF\\n        idx = int(i*numOfBatches+j+1)\\n        beta0[idx] = x_i[0]\\n        beta1[idx] = x_i[1]\\n\\n        fig = plt.figure(figsize=(14,6))\\n        ax1 = fig.add_subplot(121)\\n        ax1.contour(A,B,s)\\n        ax1.plot(beta0[:idx+1],beta1[:idx+1],color='r')\\n        ax1.scatter(beta0[:idx+1],beta1[:idx+1],color='k')\\n        ax1.scatter(intercept, slope, color='r')\\n        ax1.set_title('Mini-Batch Gradient Descent')\\n        ax2 = fig.add_subplot(122)\\n        ax2.scatter(x1,y)\\n        ax2.plot(x1,beta0[idx]+beta1[idx]*x1,color='r')\\n        #fig.savefig('figure/miniBatch_'+str(i)+'_'+str(j)+'.png')\\n        plt.pause(0.1) # number of seconds before updating the graph\\n        plt.show()\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T10:48:51.590449Z",
     "start_time": "2025-06-24T10:48:32.168661Z"
    }
   },
   "source": [
    "nIters = 1\n",
    "g1 = 0.1 # learning rate\n",
    "intercept_ = 40\n",
    "slope_ = -50\n",
    "x_i = np.array([intercept_,slope_])\n",
    "\n",
    "batchSize = 1\n",
    "#numOfBatches = np.ceil(lenT/batchSize)\n",
    "numOfBatches = 25\n",
    "\n",
    "beta0 = np.zeros(int(nIters*numOfBatches+1))\n",
    "beta1 = np.zeros(int(nIters*numOfBatches+1))\n",
    "beta0[0] = intercept_\n",
    "beta1[0] = slope_\n",
    "\n",
    "for i in np.arange(nIters):\n",
    "    for j in np.arange(numOfBatches): \n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        start = int(j*batchSize)\n",
    "        finish =int(min((j+1)*batchSize, lenT-1))\n",
    "        \n",
    "        xHat = x1[start:finish]\n",
    "        yHat = y[start:finish]\n",
    "        delF = gradF2(x_i, yHat, xHat);\n",
    "        \n",
    "        for i1 in np.arange(len1): \n",
    "            for j1 in np.arange(len2):\n",
    "                s[j1,i1] = np.sum((yHat-a[i1]-b[j1]*xHat)**2)/batchSize\n",
    "        \n",
    "        x_i = x_i - g1*delF\n",
    "        idx = int(i*numOfBatches+j+1)\n",
    "        beta0[idx] = x_i[0]\n",
    "        beta1[idx] = x_i[1]\n",
    "        \n",
    "        fig = plt.figure(figsize=(14,6))\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.contour(A,B,s)\n",
    "        ax1.plot(beta0[:idx+1],beta1[:idx+1],color='r')\n",
    "        ax1.scatter(beta0[:idx+1],beta1[:idx+1],color='k')\n",
    "        ax1.scatter(intercept, slope, color='r')\n",
    "        ax1.set_title('Stochastic Gradient Descent')\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.scatter(x1,y)\n",
    "        ax2.plot(x1,beta0[idx]+beta1[idx]*x1,color='r')\n",
    "        #fig.savefig('figure/miniBatch_'+str(i)+'_'+str(j)+'.png')\n",
    "        plt.pause(0.1) # number of seconds before updating the graph\n",
    "        plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnIters = 1\\ng1 = 0.1 # learning rate\\nintercept_ = 40\\nslope_ = -50\\nx_i = np.array([intercept_,slope_])\\n\\nbatchSize = 1\\n#numOfBatches = np.ceil(lenT/batchSize)\\nnumOfBatches = 25\\n\\nbeta0 = np.zeros(int(nIters*numOfBatches+1))\\nbeta1 = np.zeros(int(nIters*numOfBatches+1))\\nbeta0[0] = intercept_\\nbeta1[0] = slope_\\n\\nfor i in np.arange(nIters):\\n    for j in np.arange(numOfBatches): \\n\\n        clear_output(wait=True)\\n\\n        start = int(j*batchSize)\\n        finish =int(min((j+1)*batchSize, lenT-1))\\n\\n        xHat = x1[start:finish]\\n        yHat = y[start:finish]\\n        delF = gradF2(x_i, yHat, xHat);\\n\\n        for i1 in np.arange(len1): \\n            for j1 in np.arange(len2):\\n                s[j1,i1] = np.sum((yHat-a[i1]-b[j1]*xHat)**2)/batchSize\\n\\n        x_i = x_i - g1*delF\\n        idx = int(i*numOfBatches+j+1)\\n        beta0[idx] = x_i[0]\\n        beta1[idx] = x_i[1]\\n\\n        fig = plt.figure(figsize=(14,6))\\n        ax1 = fig.add_subplot(121)\\n        ax1.contour(A,B,s)\\n        ax1.plot(beta0[:idx+1],beta1[:idx+1],color='r')\\n        ax1.scatter(beta0[:idx+1],beta1[:idx+1],color='k')\\n        ax1.scatter(intercept, slope, color='r')\\n        ax1.set_title('Stochastic Gradient Descent')\\n        ax2 = fig.add_subplot(122)\\n        ax2.scatter(x1,y)\\n        ax2.plot(x1,beta0[idx]+beta1[idx]*x1,color='r')\\n        #fig.savefig('figure/miniBatch_'+str(i)+'_'+str(j)+'.png')\\n        plt.pause(0.1) # number of seconds before updating the graph\\n        plt.show()\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
